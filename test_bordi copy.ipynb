{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility functions and imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import pywt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "from scipy.fft import dct, idct\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import convolve2d\n",
    "from math import sqrt\n",
    "\n",
    "def wpsnr(img1, img2):\n",
    "  img1 = np.float32(img1)/255.0\n",
    "  img2 = np.float32(img2)/255.0\n",
    "  difference = img1-img2\n",
    "  same = not np.any(difference)\n",
    "  if same is True:\n",
    "      return 9999999\n",
    "  w = np.genfromtxt('csf.csv', delimiter=',')\n",
    "  ew = convolve2d(difference, np.rot90(w,2), mode='valid')\n",
    "  decibels = 20.0*np.log10(1.0/sqrt(np.mean(np.mean(ew**2))))\n",
    "  return decibels\n",
    "\n",
    "def similarity(X,X_star):\n",
    "    #Computes the similarity measure between the original and the new watermarks.\n",
    "    s = np.sum(np.multiply(X, X_star)) / (np.sqrt(np.sum(np.multiply(X, X))) * np.sqrt(np.sum(np.multiply(X_star, X_star))))\n",
    "    return s\n",
    "\n",
    "def compute_thr(sim, mark, mark_size=1024, N=1000):\n",
    "    SIM = np.zeros(N)\n",
    "    for i in range(N):\n",
    "        r = np.random.uniform(0.0, 1.0, mark_size)\n",
    "        SIM[i] = (similarity(mark, r))\n",
    "    SIMs = SIM.copy()\n",
    "    SIM.sort()\n",
    "    t = SIM[-1]\n",
    "    T = t + (0.1*t)\n",
    "    print('Threshold: ', T)\n",
    "    return T, SIMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#List of different attacks\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "import random\n",
    "\n",
    "#this seed was set just to make you obtain the same result\n",
    "random.seed(3)\n",
    "def awgn(img, std, seed):\n",
    "  mean = 0.0   # some constant\n",
    "  #np.random.seed(seed)\n",
    "  attacked = img + np.random.normal(mean, std, img.shape)\n",
    "  attacked = np.clip(attacked, 0, 255)\n",
    "  return attacked\n",
    "\n",
    "def blur(img, sigma):\n",
    "  from scipy.ndimage.filters import gaussian_filter\n",
    "  attacked = gaussian_filter(img, sigma)\n",
    "  return attacked\n",
    "\n",
    "def sharpening(img, sigma, alpha):\n",
    "  import scipy\n",
    "  from scipy.ndimage import gaussian_filter\n",
    "  import matplotlib.pyplot as plt\n",
    "\n",
    "  #print(img/255)\n",
    "  filter_blurred_f = gaussian_filter(img, sigma)\n",
    "\n",
    "  attacked = img + alpha * (img - filter_blurred_f)\n",
    "  return attacked\n",
    "\n",
    "def median(img, kernel_size):\n",
    "  from scipy.signal import medfilt\n",
    "  attacked = medfilt(img, kernel_size)\n",
    "  return attacked\n",
    "\n",
    "def resizing(img, scale):\n",
    "  from skimage.transform import rescale\n",
    "  x, y = img.shape\n",
    "  attacked = rescale(img, scale)\n",
    "  attacked = rescale(attacked, 1/scale)\n",
    "  attacked = attacked[:x, :y]\n",
    "  return attacked\n",
    "\n",
    "def jpeg_compression(img, QF):\n",
    "  from PIL import Image\n",
    "  img = Image.fromarray(img)\n",
    "  img = img.convert('L')\n",
    "  img.save('tmp.jpg',\"JPEG\", quality=QF)\n",
    "  attacked = Image.open('tmp.jpg')\n",
    "  attacked = np.asarray(attacked,dtype=np.uint8)\n",
    "  os.remove('tmp.jpg')\n",
    "\n",
    "  return attacked"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fourth technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1792\n",
      "1792\n",
      "<class 'str'>\n",
      "Original 1024-bit string: 110101011010110101011010110101011010110101011010110101011010...\n",
      "Encoded string (7,4 Hamming blocks): 101000100000011011010101000101001011010000001010001001010011000101010000000010010000001000000001000001010...\n",
      "Encoded length: 1792 bits\n"
     ]
    }
   ],
   "source": [
    "def calculate_parity_bits(data_bits):\n",
    "    \"\"\"Calculate the parity bits for a 4-bit data message.\"\"\"\n",
    "    p1 = data_bits[0] ^ data_bits[1] ^ data_bits[3]  # Parity for bits 1, 3, 5, 7\n",
    "    p2 = data_bits[0] ^ data_bits[2] ^ data_bits[3]  # Parity for bits 2, 3, 6, 7\n",
    "    p3 = data_bits[1] ^ data_bits[2] ^ data_bits[3]  # Parity for bits 4, 5, 6, 7\n",
    "    return [p1, p2, p3]\n",
    "\n",
    "def hamming_encode(data_bits):\n",
    "    \"\"\"Encode 4 data bits into a 7-bit Hamming (7,4) code.\"\"\"\n",
    "    if len(data_bits) != 4:\n",
    "        raise ValueError(\"Input must be a list of 4 data bits.\")\n",
    "    \n",
    "    # Calculate parity bits\n",
    "    p1, p2, p3 = calculate_parity_bits(data_bits)\n",
    "    \n",
    "    # Arrange the codeword: [p1, p2, data1, p3, data2, data3, data4]\n",
    "    codeword = [p1, p2, data_bits[0], p3, data_bits[1], data_bits[2], data_bits[3]]\n",
    "    \n",
    "    return codeword\n",
    "\n",
    "def split_into_blocks(bit_string, block_size=4):\n",
    "    \"\"\"Split the bit string into blocks of size block_size.\"\"\"\n",
    "    return [bit_string[i:i + block_size] for i in range(0, len(bit_string), block_size)]\n",
    "\n",
    "def encode_1024_bit_string(bit_string):\n",
    "    \"\"\"Encode a 1024-bit string using Hamming (7,4) encoding in blocks of 4 bits.\"\"\"\n",
    "    if len(bit_string) != 1024:\n",
    "        raise ValueError(\"Input string must be exactly 1024 bits long.\")\n",
    "    \n",
    "    # Split the bit string into 4-bit blocks\n",
    "    blocks = split_into_blocks(bit_string, 4)\n",
    "    \n",
    "    # Prepare to store the encoded blocks\n",
    "    encoded_blocks = []\n",
    "    \n",
    "    # Encode each 4-bit block using Hamming (7,4)\n",
    "    for block in blocks:\n",
    "        # Convert each 4-bit block (string) into a list of integers\n",
    "        data_bits = [int(bit) for bit in block]\n",
    "        \n",
    "        # Encode the block and add the resulting 7-bit codeword to encoded_blocks\n",
    "        encoded_blocks.append(hamming_encode(data_bits))\n",
    "    \n",
    "    # Flatten the list of encoded blocks into a single list of bits\n",
    "    encoded_bits = [bit for block in encoded_blocks for bit in block]\n",
    "    \n",
    "    # Convert the list of bits into a string\n",
    "    encoded_string = ''.join(map(str, encoded_bits))\n",
    "    \n",
    "    return encoded_string\n",
    "\n",
    "# Example usage:\n",
    "bit_string = '110101011010' * 85 + '0' * 4  # Example 1024-bit string (repeated pattern)\n",
    "encoded_result = encode_1024_bit_string(bit_string)\n",
    "\n",
    "print(len(encoded_result))\n",
    "encoded_list = list(encoded_result)\n",
    "print(len(encoded_list))\n",
    "\n",
    "for _ in range(512):\n",
    "    encoded_list[np.random.randint(0, 1023)] = np.random.randint(0, 1)\n",
    "\n",
    "encoded_result = \"\".join([str(x) for x in encoded_list])\n",
    "print(type(encoded_result))\n",
    "\n",
    "print(f\"Original 1024-bit string: {bit_string[:60]}...\")  # Print a small portion for brevity\n",
    "print(f\"Encoded string (7,4 Hamming blocks): {encoded_result[:105]}...\")  # Print a small portion for brevity\n",
    "print(f\"Encoded length: {len(encoded_result)} bits\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoded 1024-bit string: 110100001010110101011000111001011001110100000000000000000010...\n",
      "Decoded length: 1024 bits\n",
      "False\n",
      "0.889377382260493\n"
     ]
    }
   ],
   "source": [
    "def hamming_decode(codeword):\n",
    "    \"\"\"Decode the 7-bit Hamming code, correct single-bit errors, and extract the original 4 data bits.\"\"\"\n",
    "    if len(codeword) != 7:\n",
    "        raise ValueError(\"Codeword must be 7 bits long.\")\n",
    "    \n",
    "    # Extract the parity and data bits\n",
    "    p1, p2, d1, p3, d2, d3, d4 = codeword\n",
    "    \n",
    "    # Recalculate the parity bits based on the received data\n",
    "    c1 = p1 ^ d1 ^ d2 ^ d4  # Check parity bit 1\n",
    "    c2 = p2 ^ d1 ^ d3 ^ d4  # Check parity bit 2\n",
    "    c3 = p3 ^ d2 ^ d3 ^ d4  # Check parity bit 3\n",
    "    \n",
    "    # Combine the parity check results into a single error syndrome\n",
    "    error_position = (c3 << 2) | (c2 << 1) | c1  # Binary value gives error position\n",
    "    \n",
    "    # If error_position is non-zero, correct the error\n",
    "    if error_position != 0:\n",
    "        codeword[error_position - 1] ^= 1  # Flip the bit at the error position\n",
    "    \n",
    "    # Extract the original data bits from the corrected codeword\n",
    "    data_bits = [codeword[2], codeword[4], codeword[5], codeword[6]]\n",
    "    \n",
    "    return data_bits\n",
    "\n",
    "def split_into_blocks(bit_string, block_size):\n",
    "    \"\"\"Split the bit string into blocks of size block_size.\"\"\"\n",
    "    return [bit_string[i:i + block_size] for i in range(0, len(bit_string), block_size)]\n",
    "\n",
    "def decode_1792_bit_string(encoded_string):\n",
    "    \"\"\"Decode a 1792-bit Hamming (7,4) encoded string back into a 1024-bit string.\"\"\"\n",
    "    if len(encoded_string) != 1792:\n",
    "        raise ValueError(\"Input string must be exactly 1792 bits long.\")\n",
    "    \n",
    "    # Split the encoded string into 7-bit blocks\n",
    "    encoded_blocks = split_into_blocks(encoded_string, 7)\n",
    "    \n",
    "    # Prepare to store the decoded data bits\n",
    "    decoded_data_bits = []\n",
    "    \n",
    "    # Decode each 7-bit block and extract the original 4 data bits\n",
    "    for block in encoded_blocks:\n",
    "        # Convert the 7-bit block (string) into a list of integers\n",
    "        codeword = [int(bit) for bit in block]\n",
    "        \n",
    "        # Decode the block to get the original 4 data bits\n",
    "        decoded_bits = hamming_decode(codeword)\n",
    "        \n",
    "        # Append the decoded 4 data bits to the result\n",
    "        decoded_data_bits.extend(decoded_bits)\n",
    "    \n",
    "    # Convert the list of decoded data bits into a string\n",
    "    decoded_string = ''.join(map(str, decoded_data_bits))\n",
    "    \n",
    "    return decoded_string\n",
    "\n",
    "# Example usage:\n",
    "decoded_result = decode_1792_bit_string(encoded_result)\n",
    "\n",
    "print(f\"Decoded 1024-bit string: {decoded_result[:60]}...\")  # Print a small portion for brevity\n",
    "print(f\"Decoded length: {len(decoded_result)} bits\")\n",
    "print(decoded_result == bit_string)\n",
    "\n",
    "print(similarity(np.asarray(list(decoded_result), dtype=np.uint8), np.asarray(list(bit_string), dtype=np.uint8)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_perceptual_mask(subband):\n",
    "\n",
    "    mask = np.ones(subband.shape)\n",
    "    mask += compute_brightness_sensitivity(subband) * compute_edge_sensitivity(subband) * compute_texture_sensitivity(subband)\n",
    "    \n",
    "    return mask\n",
    "\n",
    "def compute_brightness_sensitivity(subband):\n",
    "\n",
    "    # Normalize brightness between 0 and 1\n",
    "    min_brightness = np.min(subband)\n",
    "    max_brightness = np.max(subband)\n",
    "    brightness_sensitivity = (subband - min_brightness) / (max_brightness - min_brightness + 1e-6)\n",
    "    \n",
    "    # Invert to give higher sensitivity in dark areas (lower brightness = higher mask value)\n",
    "    return 1 - brightness_sensitivity\n",
    "\n",
    "def compute_edge_sensitivity(subband):\n",
    "\n",
    "    # Compute image gradient (strong edges correspond to higher gradients)\n",
    "    sobel_x = cv2.Sobel(subband, cv2.CV_64F, 1, 0, ksize=3)\n",
    "    sobel_y = cv2.Sobel(subband, cv2.CV_64F, 0, 1, ksize=3)\n",
    "    gradient_magnitude = np.sqrt(sobel_x**2 + sobel_y**2)\n",
    "    \n",
    "    # Normalize gradient magnitude between 0 and 1\n",
    "    gradient_sensitivity = (gradient_magnitude - np.min(gradient_magnitude)) / (np.max(gradient_magnitude) - np.min(gradient_magnitude) + 1e-6)\n",
    "    \n",
    "    return gradient_sensitivity\n",
    "\n",
    "def compute_texture_sensitivity(subband):\n",
    "    \n",
    "    # Compute local variance as a measure of texture\n",
    "    mean = cv2.blur(subband, (3, 3))\n",
    "    local_variance = cv2.blur((subband - mean) ** 2, (3, 3))\n",
    "    \n",
    "    # Normalize local variance between 0 and 1\n",
    "    texture_sensitivity = (local_variance - np.min(local_variance)) / (np.max(local_variance) - np.min(local_variance) + 1e-6)\n",
    "    \n",
    "    return texture_sensitivity\n",
    "\n",
    "def modular_alpha(layer, theta, alpha):\n",
    "    arrayLayer = [1.0, 0.32, 0.16, 0.1]\n",
    "    arrayTheta = [1, sqrt(2), 1]\n",
    "\n",
    "    return alpha * arrayLayer[layer] * arrayTheta[theta]\n",
    "\n",
    "def get_locations(subband):\n",
    "    sign = np.sign(subband)\n",
    "    abs_subband = abs(subband)\n",
    "    locations = np.argsort(-abs_subband, axis=None) # - sign is used to get descending order\n",
    "    rows = subband.shape[0]\n",
    "    locations = [(val//rows, val%rows) for val in locations] # locations as (x,y) coordinates\n",
    "\n",
    "    return abs_subband, sign, locations\n",
    "\n",
    "def embed_watermark(subband, mark, layer, theta, alpha=0.5, v='multiplicative'):\n",
    "\n",
    "    mask = create_perceptual_mask(subband)\n",
    "    abs_subband, sign, locations = get_locations(subband) \n",
    "\n",
    "    watermarked = abs_subband.copy()\n",
    "    for idx, (loc, mark_val) in enumerate(zip(locations[1:], mark)):\n",
    "        x = locations[idx][0]\n",
    "        y = locations[idx][1]\n",
    "        if v == 'additive':\n",
    "            watermarked[loc] += (modular_alpha(layer, theta, alpha) * mark_val * mask[x][y])\n",
    "        elif v == 'multiplicative':\n",
    "            watermarked[loc] *= 1 + (modular_alpha(layer, theta, alpha) * mark_val * mask[x][y])\n",
    "    \n",
    "    return sign * watermarked\n",
    "\n",
    "def recursive_embedding(coeffs, mark, alpha, layer, max_layer, v='multiplicative'):\n",
    "    LL, (LH, HL, HH) = coeffs\n",
    "\n",
    "    # Base case: if we reach layer 3, embed the watermark and return\n",
    "    if layer == max_layer:\n",
    "        watermarked_LH = embed_watermark(LH, mark, layer, 0, alpha, v)\n",
    "        watermarked_HL = embed_watermark(HL, mark, layer, 2, alpha, v)\n",
    "        watermarked_HH = embed_watermark(HH, mark, layer, 1, alpha, v)\n",
    "\n",
    "        watermarked_LL = pywt.idwt2((LL, (watermarked_LH, watermarked_HL, watermarked_HH)), 'haar')\n",
    "        return watermarked_LL\n",
    "\n",
    "    # Recursive case: perform another DWT and recurse\n",
    "    coeffs_next = pywt.dwt2(LL, 'haar')\n",
    "    watermarked_LL = recursive_embedding(coeffs_next, mark, alpha, layer + 1, max_layer, v)\n",
    "\n",
    "    # Embed the watermark at this layer\n",
    "    watermarked_LH = embed_watermark(LH, mark, layer, 0, alpha, v)\n",
    "    watermarked_HL = embed_watermark(HL, mark, layer, 2, alpha, v)\n",
    "    watermarked_HH = embed_watermark(HH, mark, layer, 1, alpha, v)\n",
    "\n",
    "    # Return the inverse DWT of the watermarked image\n",
    "    watermarked = pywt.idwt2((watermarked_LL, (watermarked_LH, watermarked_HL, watermarked_HH)), 'haar')\n",
    "    return watermarked\n",
    "\n",
    "\n",
    "def embedding(image, mark, alpha, max_layer=2, v='multiplicative'):\n",
    "    # Initial wavelet decomposition\n",
    "    coeffs = pywt.dwt2(image, 'haar')\n",
    "\n",
    "    mark = \"\".join([str(x) for x in mark])\n",
    "    enc_mark = encode_1024_bit_string(mark)\n",
    "    enc_mark = np.asarray(list(enc_mark), dtype=np.uint8)\n",
    "    # Start recursive embedding from layer 0\n",
    "    watermarked_image = recursive_embedding(coeffs, enc_mark, alpha, layer=0, max_layer=max_layer, v=v)\n",
    "    \n",
    "    return watermarked_image\n",
    "\n",
    "\n",
    "def extract_watermark(subband, watermarked_subband, layer, theta, alpha=0.5, v='multiplicative'):\n",
    "    # Create perceptual mask for the subband\n",
    "    mask = create_perceptual_mask(subband)\n",
    "    abs_subband, sign, locations = get_locations(subband)\n",
    "    abs_watermarked, _, _ = get_locations(watermarked_subband)\n",
    "    mark_size = 1792\n",
    "\n",
    "    extracted_mark = np.zeros(mark_size, dtype=np.float64)\n",
    "\n",
    "    # Loop through each location (except the first one)\n",
    "    for idx, loc in enumerate(locations[1:mark_size+1]):\n",
    "        x = locations[idx][0]\n",
    "        y = locations[idx][1]\n",
    "        \n",
    "        if v == 'additive':\n",
    "            # Reverse the additive watermarking process to extract the mark\n",
    "            extracted_mark[idx] = (watermarked_subband[loc] - subband[loc]) / (modular_alpha(layer, theta, alpha) * mask[x][y])\n",
    "        elif v == 'multiplicative':\n",
    "            # Reverse the multiplicative watermarking process to extract the mark\n",
    "            extracted_mark[idx] = (watermarked_subband[loc] - subband[loc]) / modular_alpha(layer, theta, alpha) * mask[x][y] * subband[loc]\n",
    "\n",
    "        \n",
    "    return  np.clip(extracted_mark, 0, 1).astype(np.uint8)\n",
    "\n",
    "def detect_wm(image, watermarked, alpha, max_layer=2, v='multiplicative'):\n",
    "    #ori_dct = dct(dct(image,axis=0, norm='ortho'),axis=1, norm='ortho')\n",
    "    LL0_or, (LH0_or, HL0_or, HH0_or) = pywt.dwt2(image, 'haar')\n",
    "    LL1_or, (LH1_or, HL1_or, HH1_or) = pywt.dwt2(LL0_or, 'haar')\n",
    "    LL2_or, (LH2_or, HL2_or, HH2_or) = pywt.dwt2(LL1_or, 'haar')\n",
    "     \n",
    "\n",
    "    #wat_dct = dct(dct(watermarked,axis=0, norm='ortho'),axis=1, norm='ortho')\n",
    "    LL0_w, (LH0_w, HL0_w, HH0_w) = pywt.dwt2(watermarked, 'haar')\n",
    "    LL1_w, (LH1_w, HL1_w, HH1_w) = pywt.dwt2(LL0_w, 'haar')\n",
    "    LL2_w, (LH2_w, HL2_w, HH2_w) = pywt.dwt2(LL1_w, 'haar')\n",
    "    \n",
    "    extracted_wms = []\n",
    "\n",
    "    if max_layer == 2:\n",
    "        extracted_wms.append(extract_watermark(LH2_or, LH2_w, 2, 0, alpha=alpha, v=v))\n",
    "        extracted_wms.append(extract_watermark(HL2_or, HL2_w, 2, 2, alpha=alpha, v=v))\n",
    "        extracted_wms.append(extract_watermark(HH2_or, HH2_w, 2, 1, alpha=alpha, v=v))\n",
    "    if max_layer >= 1:\n",
    "        extracted_wms.append(extract_watermark(LH1_or, LH1_w, 1, 0, alpha=alpha, v=v))\n",
    "        extracted_wms.append(extract_watermark(HL1_or, HL1_w, 1, 2, alpha=alpha, v=v))\n",
    "        extracted_wms.append(extract_watermark(HH1_or, HH1_w, 1, 1, alpha=alpha, v=v))\n",
    "\n",
    "    extracted_wms.append(extract_watermark(LH0_or, LH0_w, 0, 0, alpha=alpha, v=v))\n",
    "    extracted_wms.append(extract_watermark(HL0_or, HL0_w, 0, 2, alpha=alpha, v=v))\n",
    "    extracted_wms.append(extract_watermark(HH0_or, HH0_w, 0, 1, alpha=alpha, v=v))\n",
    "\n",
    "    return extracted_wms\n",
    "\n",
    "def detection(original, watermarked, attacked, alpha, max_layer):\n",
    "    w_ex = detect_wm(original, watermarked, alpha, max_layer=max_layer)\n",
    "    w_ex_attacked = detect_wm(original, attacked, alpha, max_layer=max_layer)\n",
    "    # w_ex_from_original = detect_wm(original, original, alpha, max_layer=max_layer)\n",
    "\n",
    "    thr = 0.7045\n",
    "    sim = []\n",
    "\n",
    "    decoded_ex_attacked = []\n",
    "    #decoded_ex_original = []\n",
    "\n",
    "    for w in w_ex_attacked:\n",
    "        w = \"\".join([str(x) for x in w])\n",
    "        decoded_w = decode_1792_bit_string(w)\n",
    "        decoded_ex_attacked.append(np.asarray(list(decoded_w), dtype=np.uint8))\n",
    "\n",
    "    # for w in w_ex_from_original:\n",
    "    #     w = \"\".join([str(x) for x in w])\n",
    "    #     decoded_w = decode_1792_bit_string(w)\n",
    "    #     decoded_ex_original.append(np.asarray(list(decoded_w), dtype=np.uint8))\n",
    "\n",
    "    ex_mark = w_ex[0]\n",
    "    ex_mark = \"\".join([str(x) for x in ex_mark])\n",
    "    decoded= decode_1792_bit_string(ex_mark)\n",
    "    ex_mark= np.asarray(list(decoded), dtype=np.uint8)\n",
    "\n",
    "\n",
    "\n",
    "    for w in decoded_ex_attacked:\n",
    "        x = similarity(w, ex_mark)\n",
    "        sim.append(x)\n",
    "\n",
    "    # sim_or = []\n",
    "    # for w in decoded_ex_original:\n",
    "    #     print(\"\".join([str(bit) for bit in w]))\n",
    "    #     x = similarity(w, decoded_ex_wm)\n",
    "    #     sim_or.append(x)\n",
    "        \n",
    "    \n",
    "    # sim_or  = max(sim_or)\n",
    "    sim = max(sim)\n",
    "\n",
    "    print(\"Similarity between the watermark and the one extracted from the attacked image\", sim)\n",
    "    print(\"Similarity between the watermark extracted and the original mark\", similarity(mark, ex_mark))    \n",
    "    \n",
    "    # print(sim_or)\n",
    "\n",
    "    if sim >= thr:\n",
    "        return 1\n",
    "    return 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(wpsnr_wm_imgs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = [cv2.imread(os.path.join('./sample_imgs', img), 0) for img in os.listdir('./sample_imgs')]\n",
    "mark = np.load('ammhackati.npy')\n",
    "wm_imgs = []\n",
    "alpha = 0.8\n",
    "max_layer = 1\n",
    "\n",
    "for img in imgs[:10]:\n",
    "    wm = embedding(img, mark, alpha=alpha, max_layer=max_layer)\n",
    "    wm_imgs.append(wm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity between the watermark and the one extracted from the attacked image 0.7563188837230259\n",
      "Similarity between the watermark extracted and the original mark 1.0\n",
      "44.4341990108891\n",
      "42.449613055813145\n",
      "Found\n",
      "=========================\n",
      "Similarity between the watermark and the one extracted from the attacked image 0.6125537409519175\n",
      "Similarity between the watermark extracted and the original mark 1.0\n",
      "52.62450673992092\n",
      "45.574971705812345\n",
      "Not found\n",
      "=========================\n",
      "Similarity between the watermark and the one extracted from the attacked image 0.6013649768019799\n",
      "Similarity between the watermark extracted and the original mark 1.0\n",
      "51.72349302557904\n",
      "45.69252075946519\n",
      "Not found\n",
      "=========================\n",
      "Similarity between the watermark and the one extracted from the attacked image 0.6802015274471576\n",
      "Similarity between the watermark extracted and the original mark 1.0\n",
      "51.9248025994368\n",
      "44.311686477256046\n",
      "Not found\n",
      "=========================\n",
      "Similarity between the watermark and the one extracted from the attacked image 0.7312019645169391\n",
      "Similarity between the watermark extracted and the original mark 1.0\n",
      "49.48658092351319\n",
      "43.37102350836027\n",
      "Found\n",
      "=========================\n",
      "Similarity between the watermark and the one extracted from the attacked image 0.6947182802074008\n",
      "Similarity between the watermark extracted and the original mark 1.0\n",
      "49.344105329376134\n",
      "45.7106971378871\n",
      "Not found\n",
      "=========================\n",
      "Similarity between the watermark and the one extracted from the attacked image 0.6884184546617799\n",
      "Similarity between the watermark extracted and the original mark 1.0\n",
      "48.71955224018958\n",
      "44.36994591075286\n",
      "Not found\n",
      "=========================\n",
      "Similarity between the watermark and the one extracted from the attacked image 0.7892691947334292\n",
      "Similarity between the watermark extracted and the original mark 1.0\n",
      "44.101506910677095\n",
      "42.218694767766614\n",
      "Found\n",
      "=========================\n",
      "Similarity between the watermark and the one extracted from the attacked image 0.7025727809000398\n",
      "Similarity between the watermark extracted and the original mark 1.0\n",
      "49.53436489709473\n",
      "45.69525025113293\n",
      "Not found\n",
      "=========================\n",
      "Similarity between the watermark and the one extracted from the attacked image 0.7486720501984933\n",
      "Similarity between the watermark extracted and the original mark 1.0\n",
      "49.150635329455106\n",
      "43.90279651429017\n",
      "Found\n",
      "=========================\n"
     ]
    }
   ],
   "source": [
    "for wi, img in zip(wm_imgs, imgs): \n",
    "    attacked = jpeg_compression(wi, 20)\n",
    "    result = detection(img, wi, attacked, alpha=alpha, max_layer=max_layer)\n",
    "    print(wpsnr(wi, img))\n",
    "    print(wpsnr(attacked, wi))\n",
    "    if result:\n",
    "        print(\"Found\")\n",
    "    else:\n",
    "        print(\"Not found\")\n",
    "    \n",
    "    print(\"=========================\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyldpc import make_ldpc, encode, decode, get_message\n",
    "\n",
    "\n",
    "def create_perceptual_mask(subband):\n",
    "\n",
    "    mask = np.ones(subband.shape)\n",
    "    mask += compute_brightness_sensitivity(subband) * compute_edge_sensitivity(subband) * compute_texture_sensitivity(subband)\n",
    "    \n",
    "    return mask\n",
    "\n",
    "def compute_brightness_sensitivity(subband):\n",
    "\n",
    "    # Normalize brightness between 0 and 1\n",
    "    min_brightness = np.min(subband)\n",
    "    max_brightness = np.max(subband)\n",
    "    brightness_sensitivity = (subband - min_brightness) / (max_brightness - min_brightness + 1e-6)\n",
    "    \n",
    "    # Invert to give higher sensitivity in dark areas (lower brightness = higher mask value)\n",
    "    return 1 - brightness_sensitivity\n",
    "\n",
    "def compute_edge_sensitivity(subband):\n",
    "\n",
    "    # Compute image gradient (strong edges correspond to higher gradients)\n",
    "    sobel_x = cv2.Sobel(subband, cv2.CV_64F, 1, 0, ksize=3)\n",
    "    sobel_y = cv2.Sobel(subband, cv2.CV_64F, 0, 1, ksize=3)\n",
    "    gradient_magnitude = np.sqrt(sobel_x**2 + sobel_y**2)\n",
    "    \n",
    "    # Normalize gradient magnitude between 0 and 1\n",
    "    gradient_sensitivity = (gradient_magnitude - np.min(gradient_magnitude)) / (np.max(gradient_magnitude) - np.min(gradient_magnitude) + 1e-6)\n",
    "    \n",
    "    return gradient_sensitivity\n",
    "\n",
    "def compute_texture_sensitivity(subband):\n",
    "    \n",
    "    # Compute local variance as a measure of texture\n",
    "    mean = cv2.blur(subband, (3, 3))\n",
    "    local_variance = cv2.blur((subband - mean) ** 2, (3, 3))\n",
    "    \n",
    "    # Normalize local variance between 0 and 1\n",
    "    texture_sensitivity = (local_variance - np.min(local_variance)) / (np.max(local_variance) - np.min(local_variance) + 1e-6)\n",
    "    \n",
    "    return texture_sensitivity\n",
    "\n",
    "def modular_alpha(layer, theta, alpha):\n",
    "    arrayLayer = [1.0, 0.32, 0.16, 0.1]\n",
    "    arrayTheta = [1, sqrt(2), 1]\n",
    "\n",
    "    return alpha * arrayLayer[layer] * arrayTheta[theta]\n",
    "\n",
    "def get_locations(subband):\n",
    "    sign = np.sign(subband)\n",
    "    abs_subband = abs(subband)\n",
    "    locations = np.argsort(-abs_subband, axis=None) # - sign is used to get descending order\n",
    "    rows = subband.shape[0]\n",
    "    locations = [(val//rows, val%rows) for val in locations] # locations as (x,y) coordinates\n",
    "\n",
    "    return abs_subband, sign, locations\n",
    "\n",
    "def embed_watermark(subband, mark, layer, theta, alpha=0.5, v='multiplicative'):\n",
    "\n",
    "    mask = create_perceptual_mask(subband)\n",
    "    abs_subband, sign, locations = get_locations(subband) \n",
    "\n",
    "    watermarked = abs_subband.copy()\n",
    "    for idx, (loc, mark_val) in enumerate(zip(locations[1:], mark)):\n",
    "        x = locations[idx][0]\n",
    "        y = locations[idx][1]\n",
    "        if v == 'additive':\n",
    "            watermarked[loc] += (modular_alpha(layer, theta, alpha) * mark_val * mask[x][y])\n",
    "        elif v == 'multiplicative':\n",
    "            watermarked[loc] *= 1 + (modular_alpha(layer, theta, alpha) * mark_val * mask[x][y])\n",
    "    \n",
    "    return sign * watermarked\n",
    "\n",
    "def recursive_embedding(coeffs, mark, alpha, layer, max_layer, v='multiplicative'):\n",
    "    LL, (LH, HL, HH) = coeffs\n",
    "\n",
    "    # Base case: if we reach layer 3, embed the watermark and return\n",
    "    if layer == max_layer:\n",
    "        watermarked_LH = embed_watermark(LH, mark, layer, 0, alpha, v)\n",
    "        watermarked_HL = embed_watermark(HL, mark, layer, 2, alpha, v)\n",
    "        watermarked_HH = embed_watermark(HH, mark, layer, 1, alpha, v)\n",
    "\n",
    "        watermarked_LL = pywt.idwt2((LL, (watermarked_LH, watermarked_HL, watermarked_HH)), 'haar')\n",
    "        return watermarked_LL\n",
    "\n",
    "    # Recursive case: perform another DWT and recurse\n",
    "    coeffs_next = pywt.dwt2(LL, 'haar')\n",
    "    watermarked_LL = recursive_embedding(coeffs_next, mark, alpha, layer + 1, max_layer, v)\n",
    "\n",
    "    # Embed the watermark at this layer\n",
    "    watermarked_LH = embed_watermark(LH, mark, layer, 0, alpha, v)\n",
    "    watermarked_HL = embed_watermark(HL, mark, layer, 2, alpha, v)\n",
    "    watermarked_HH = embed_watermark(HH, mark, layer, 1, alpha, v)\n",
    "\n",
    "    # Return the inverse DWT of the watermarked image\n",
    "    watermarked = pywt.idwt2((watermarked_LL, (watermarked_LH, watermarked_HL, watermarked_HH)), 'haar')\n",
    "    return watermarked\n",
    "\n",
    "\n",
    "def embedding(image, mark, alpha, max_layer=2, v='multiplicative'):\n",
    "\n",
    "    n = 2048\n",
    "    d_v = 4\n",
    "    d_c = 8\n",
    "    snr = 20\n",
    "\n",
    "    _, G = make_ldpc(n, d_v, d_c, systematic=True, sparse=True)\n",
    "    mark = np.append(mark, [0,0,0])\n",
    "    encoded_mark = encode(G, mark, snr)\n",
    "\n",
    "    print(len(encoded_mark))\n",
    "    # Initial wavelet decomposition\n",
    "    coeffs = pywt.dwt2(image, 'haar')\n",
    "    # Start recursive embedding from layer 0\n",
    "    watermarked_image = recursive_embedding(coeffs, encoded_mark, alpha, layer=0, max_layer=max_layer, v=v)\n",
    "    \n",
    "    return watermarked_image\n",
    "\n",
    "\n",
    "def extract_watermark(subband, watermarked_subband, layer, theta, alpha=0.5, v='multiplicative'):\n",
    "    # Create perceptual mask for the subband\n",
    "    mask = create_perceptual_mask(subband)\n",
    "    abs_subband, sign, locations = get_locations(subband)\n",
    "    abs_watermarked, _, _ = get_locations(watermarked_subband)\n",
    "    mark_size = 2048\n",
    "\n",
    "    extracted_mark = np.zeros(mark_size, dtype=np.float64)\n",
    "\n",
    "    # Loop through each location (except the first one)\n",
    "    for idx, loc in enumerate(locations[1:mark_size+1]):\n",
    "        x = locations[idx][0]\n",
    "        y = locations[idx][1]\n",
    "        \n",
    "        if v == 'additive':\n",
    "            # Reverse the additive watermarking process to extract the mark\n",
    "            extracted_mark[idx] = (watermarked_subband[loc] - subband[loc]) / (modular_alpha(layer, theta, alpha) * mask[x][y])\n",
    "        elif v == 'multiplicative':\n",
    "            # Reverse the multiplicative watermarking process to extract the mark\n",
    "            extracted_mark[idx] = (watermarked_subband[loc] - subband[loc]) / modular_alpha(layer, theta, alpha) * mask[x][y] * subband[loc]\n",
    "\n",
    "\n",
    "        \n",
    "    return  np.clip(extracted_mark, 0, 1).astype(np.uint8)\n",
    "\n",
    "def detect_wm(image, watermarked, alpha, max_layer=2, v='multiplicative'):\n",
    "    #ori_dct = dct(dct(image,axis=0, norm='ortho'),axis=1, norm='ortho')\n",
    "    LL0_or, (LH0_or, HL0_or, HH0_or) = pywt.dwt2(image, 'haar')\n",
    "    LL1_or, (LH1_or, HL1_or, HH1_or) = pywt.dwt2(LL0_or, 'haar')\n",
    "    LL2_or, (LH2_or, HL2_or, HH2_or) = pywt.dwt2(LL1_or, 'haar')\n",
    "     \n",
    "\n",
    "    #wat_dct = dct(dct(watermarked,axis=0, norm='ortho'),axis=1, norm='ortho')\n",
    "    LL0_w, (LH0_w, HL0_w, HH0_w) = pywt.dwt2(watermarked, 'haar')\n",
    "    LL1_w, (LH1_w, HL1_w, HH1_w) = pywt.dwt2(LL0_w, 'haar')\n",
    "    LL2_w, (LH2_w, HL2_w, HH2_w) = pywt.dwt2(LL1_w, 'haar')\n",
    "    \n",
    "    extracted_wms = []\n",
    "\n",
    "    if max_layer == 2:\n",
    "        extracted_wms.append(extract_watermark(LH2_or, LH2_w, 2, 0, alpha=alpha, v=v))\n",
    "        extracted_wms.append(extract_watermark(HL2_or, HL2_w, 2, 2, alpha=alpha, v=v))\n",
    "        extracted_wms.append(extract_watermark(HH2_or, HH2_w, 2, 1, alpha=alpha, v=v))\n",
    "    if max_layer >= 1:\n",
    "        extracted_wms.append(extract_watermark(LH1_or, LH1_w, 1, 0, alpha=alpha, v=v))\n",
    "        extracted_wms.append(extract_watermark(HL1_or, HL1_w, 1, 2, alpha=alpha, v=v))\n",
    "        extracted_wms.append(extract_watermark(HH1_or, HH1_w, 1, 1, alpha=alpha, v=v))\n",
    "\n",
    "    extracted_wms.append(extract_watermark(LH0_or, LH0_w, 0, 0, alpha=alpha, v=v))\n",
    "    extracted_wms.append(extract_watermark(HL0_or, HL0_w, 0, 2, alpha=alpha, v=v))\n",
    "    extracted_wms.append(extract_watermark(HH0_or, HH0_w, 0, 1, alpha=alpha, v=v))\n",
    "\n",
    "    return extracted_wms\n",
    "\n",
    "def detection(original, watermarked, attacked, alpha, max_layer):\n",
    "    w_ex = detect_wm(original, watermarked, alpha, max_layer=max_layer)\n",
    "    w_ex_attacked = detect_wm(original, attacked, alpha, max_layer=max_layer)\n",
    "    thr = 0.7045\n",
    "    sim = []\n",
    "    n = 2048\n",
    "    d_v = 4\n",
    "    d_c = 8\n",
    "    snr = 10\n",
    "    H, G = make_ldpc(n, d_v, d_c, systematic=True, sparse=True)\n",
    "    ex_mark = []\n",
    "\n",
    "    w_ex_attacked_decoded = []\n",
    "    for w in w_ex_attacked:\n",
    "        decoded = decode(H, w, snr, maxiter=100)\n",
    "        decoded = get_message(G, decoded)\n",
    "        decoded = np.delete(decoded, np.s_[-3:])\n",
    "        w_ex_attacked_decoded.append(decoded)\n",
    "\n",
    "    # decoded = decode(H, w_ex_attacked[3], snr, maxiter=10)\n",
    "    # decoded = get_message(G, decoded)\n",
    "    # decoded = np.delete(decoded, np.s_[-3:])\n",
    "    # w_ex_att = decoded\n",
    "\n",
    "    \n",
    "    decoded = decode(H, w_ex[1], snr)\n",
    "    decoded = get_message(G, decoded)\n",
    "    decoded = np.delete(decoded, np.s_[-3:])\n",
    "    ex_mark = decoded\n",
    "    \n",
    "    for w in w_ex_attacked_decoded:\n",
    "        x = similarity(w, ex_mark)\n",
    "        sim.append(x)    \n",
    "    sim = max(sim)\n",
    "\n",
    "    # sim = similarity(ex_mark, w_ex_att)\n",
    "\n",
    "    print(sim)\n",
    "    print(\"Similarity mark and extracted mark: \", similarity(ex_mark, mark))\n",
    "\n",
    "    if sim >= thr:\n",
    "        return 1\n",
    "    return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2048\n",
      "52.97070296877771\n",
      "2048\n",
      "60.81587521371497\n",
      "2048\n",
      "61.1596742006098\n",
      "2048\n",
      "59.757621894466915\n",
      "2048\n",
      "56.94168990420093\n",
      "2048\n",
      "57.42169689587178\n",
      "2048\n",
      "57.553888534908566\n",
      "2048\n",
      "51.73778159665592\n",
      "2048\n",
      "58.41393258613817\n",
      "2048\n",
      "57.27067931150731\n"
     ]
    }
   ],
   "source": [
    "imgs = [cv2.imread(os.path.join('./sample_imgs', img), 0) for img in os.listdir('./sample_imgs')]\n",
    "mark = np.load('ammhackati.npy')\n",
    "wm_imgs = []\n",
    "alpha = 0.3\n",
    "max_layer = 1\n",
    "wpsnr_wm =[]\n",
    "\n",
    "for img in imgs[:10]:\n",
    "    wm = embedding(img, mark, alpha=alpha, max_layer=max_layer)\n",
    "    wm_imgs.append(wm)\n",
    "    wpsnr_wm.append(wpsnr(img, wm))\n",
    "    print(wpsnr_wm[-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avarage wpsnr:  57.38347234549227\n",
      "[1 1 1 ... 1 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sh4ring4n/.conda/envs/OFF_MDS_ENV/lib/python3.8/site-packages/pyldpc/decoder.py:62: UserWarning: Decoding stopped before convergence. You may want\n",
      "                       to increase maxiter\n",
      "  warnings.warn(\"\"\"Decoding stopped before convergence. You may want\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6893573387803132\n",
      "Similarity mark and extracted mark:  0.9813067629253163\n",
      "Not found\n"
     ]
    }
   ],
   "source": [
    "attacked = jpeg_compression(wm_imgs[0], 5)\n",
    "print(\"avarage wpsnr: \", np.mean(wpsnr_wm))\n",
    "print(mark)\n",
    "result = detection(imgs[0], wm_imgs[0], attacked, alpha=alpha, max_layer=max_layer)\n",
    "if result:\n",
    "    print(\"Found\")\n",
    "else:\n",
    "    print(\"Not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for wi, img in zip(wm_imgs, imgs): \n",
    "    attacked = jpeg_compression(wi, 5)\n",
    "    result = detection(img, wi, attacked, alpha=alpha, max_layer=max_layer)\n",
    "    print(wpsnr(attacked, wi))\n",
    "    if result:\n",
    "        print(\"Found\")\n",
    "    else:\n",
    "        print(\"Not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import reedsolo\n",
    "\n",
    "symbols = 190\n",
    "\n",
    "def create_perceptual_mask(subband):\n",
    "\n",
    "    mask = np.ones(subband.shape)\n",
    "    mask += compute_brightness_sensitivity(subband) * compute_edge_sensitivity(subband) * compute_texture_sensitivity(subband)\n",
    "    \n",
    "    return mask\n",
    "\n",
    "def compute_brightness_sensitivity(subband):\n",
    "\n",
    "    # Normalize brightness between 0 and 1\n",
    "    min_brightness = np.min(subband)\n",
    "    max_brightness = np.max(subband)\n",
    "    brightness_sensitivity = (subband - min_brightness) / (max_brightness - min_brightness + 1e-6)\n",
    "    \n",
    "    # Invert to give higher sensitivity in dark areas (lower brightness = higher mask value)\n",
    "    return 1 - brightness_sensitivity\n",
    "\n",
    "def compute_edge_sensitivity(subband):\n",
    "\n",
    "    # Compute image gradient (strong edges correspond to higher gradients)\n",
    "    sobel_x = cv2.Sobel(subband, cv2.CV_64F, 1, 0, ksize=3)\n",
    "    sobel_y = cv2.Sobel(subband, cv2.CV_64F, 0, 1, ksize=3)\n",
    "    gradient_magnitude = np.sqrt(sobel_x**2 + sobel_y**2)\n",
    "    \n",
    "    # Normalize gradient magnitude between 0 and 1\n",
    "    gradient_sensitivity = (gradient_magnitude - np.min(gradient_magnitude)) / (np.max(gradient_magnitude) - np.min(gradient_magnitude) + 1e-6)\n",
    "    \n",
    "    return gradient_sensitivity\n",
    "\n",
    "def compute_texture_sensitivity(subband):\n",
    "    \n",
    "    # Compute local variance as a measure of texture\n",
    "    mean = cv2.blur(subband, (3, 3))\n",
    "    local_variance = cv2.blur((subband - mean) ** 2, (3, 3))\n",
    "    \n",
    "    # Normalize local variance between 0 and 1\n",
    "    texture_sensitivity = (local_variance - np.min(local_variance)) / (np.max(local_variance) - np.min(local_variance) + 1e-6)\n",
    "    \n",
    "    return texture_sensitivity\n",
    "\n",
    "def modular_alpha(layer, theta, alpha):\n",
    "    arrayLayer = [1.0, 0.32, 0.16, 0.1]\n",
    "    arrayTheta = [1, sqrt(2), 1]\n",
    "\n",
    "    return alpha * arrayLayer[layer] * arrayTheta[theta]\n",
    "\n",
    "def get_locations(subband):\n",
    "    sign = np.sign(subband)\n",
    "    abs_subband = abs(subband)\n",
    "    locations = np.argsort(-abs_subband, axis=None) # - sign is used to get descending order\n",
    "    rows = subband.shape[0]\n",
    "    locations = [(val//rows, val%rows) for val in locations] # locations as (x,y) coordinates\n",
    "\n",
    "    return abs_subband, sign, locations\n",
    "\n",
    "def embed_watermark(subband, mark, layer, theta, alpha=0.5, v='multiplicative'):\n",
    "\n",
    "    mask = create_perceptual_mask(subband)\n",
    "    abs_subband, sign, locations = get_locations(subband) \n",
    "\n",
    "    watermarked = abs_subband.copy()\n",
    "    for idx, (loc, mark_val) in enumerate(zip(locations[1:], mark)):\n",
    "        x = locations[idx][0]\n",
    "        y = locations[idx][1]\n",
    "        if v == 'additive':\n",
    "            watermarked[loc] += (modular_alpha(layer, theta, alpha) * mark_val * mask[x][y])\n",
    "        elif v == 'multiplicative':\n",
    "            watermarked[loc] *= 1 + (modular_alpha(layer, theta, alpha) * mark_val * mask[x][y])\n",
    "    \n",
    "    return sign * watermarked\n",
    "\n",
    "def recursive_embedding(coeffs, mark, alpha, layer, max_layer, v='multiplicative'):\n",
    "    LL, (LH, HL, HH) = coeffs\n",
    "\n",
    "    # Base case: if we reach layer 3, embed the watermark and return\n",
    "    if layer == max_layer:\n",
    "        watermarked_LH = embed_watermark(LH, mark, layer, 0, alpha, v)\n",
    "        watermarked_HL = embed_watermark(HL, mark, layer, 2, alpha, v)\n",
    "        watermarked_HH = embed_watermark(HH, mark, layer, 1, alpha, v)\n",
    "\n",
    "        watermarked_LL = pywt.idwt2((LL, (watermarked_LH, watermarked_HL, watermarked_HH)), 'haar')\n",
    "        return watermarked_LL\n",
    "\n",
    "    # Recursive case: perform another DWT and recurse\n",
    "    coeffs_next = pywt.dwt2(LL, 'haar')\n",
    "    watermarked_LL = recursive_embedding(coeffs_next, mark, alpha, layer + 1, max_layer, v)\n",
    "\n",
    "    # Embed the watermark at this layer\n",
    "    watermarked_LH = embed_watermark(LH, mark, layer, 0, alpha, v)\n",
    "    watermarked_HL = embed_watermark(HL, mark, layer, 2, alpha, v)\n",
    "    watermarked_HH = embed_watermark(HH, mark, layer, 1, alpha, v)\n",
    "\n",
    "    # Return the inverse DWT of the watermarked image\n",
    "    watermarked = pywt.idwt2((watermarked_LL, (watermarked_LH, watermarked_HL, watermarked_HH)), 'haar')\n",
    "    return watermarked\n",
    "\n",
    "\n",
    "def embedding(image, mark, alpha, max_layer=2, v='multiplicative'):\n",
    "    rs = reedsolo.RSCodec(symbols)\n",
    "\n",
    "    encoded_mark = rs.encode(mark.tobytes())\n",
    "    \n",
    "    encoded_mark = np.array(encoded_mark)\n",
    "\n",
    "    encoded_mark = np.clip(encoded_mark, 0, 1).astype(np.uint8)\n",
    "    \n",
    "    print(len(encoded_mark))\n",
    "    # Initial wavelet decomposition\n",
    "    coeffs = pywt.dwt2(image, 'haar')\n",
    "    # Start recursive embedding from layer 0\n",
    "    watermarked_image = recursive_embedding(coeffs, encoded_mark, alpha, layer=0, max_layer=max_layer, v=v)\n",
    "    \n",
    "    return watermarked_image\n",
    "\n",
    "\n",
    "def extract_watermark(subband, watermarked_subband, layer, theta, alpha=0.5, v='multiplicative'):\n",
    "    # Create perceptual mask for the subband\n",
    "    mask = create_perceptual_mask(subband)\n",
    "    abs_subband, sign, locations = get_locations(subband)\n",
    "    abs_watermarked, _, _ = get_locations(watermarked_subband)\n",
    "    mark_size = 4064\n",
    "\n",
    "    extracted_mark = np.zeros(mark_size, dtype=np.float64)\n",
    "\n",
    "    # Loop through each location (except the first one)\n",
    "    for idx, loc in enumerate(locations[1:mark_size+1]):\n",
    "        x = locations[idx][0]\n",
    "        y = locations[idx][1]\n",
    "        \n",
    "        if v == 'additive':\n",
    "            # Reverse the additive watermarking process to extract the mark\n",
    "            extracted_mark[idx] = (watermarked_subband[loc] - subband[loc]) / (modular_alpha(layer, theta, alpha) * mask[x][y])\n",
    "        elif v == 'multiplicative':\n",
    "            # Reverse the multiplicative watermarking process to extract the mark\n",
    "            # extracted_mark[idx] = ((watermarked_subband[loc] / subband[loc]) - 1) / (modular_alpha(layer, theta, alpha) * mask[x][y])\n",
    "            extracted_mark[idx] = (watermarked_subband[loc] - subband[loc]) / modular_alpha(layer, theta, alpha) * mask[x][y] * subband[loc]\n",
    "\n",
    "\n",
    "        \n",
    "    return  np.clip(extracted_mark, 0, 1).astype(np.uint8)\n",
    "\n",
    "def detect_wm(image, watermarked, alpha, max_layer=2, v='multiplicative'):\n",
    "    #ori_dct = dct(dct(image,axis=0, norm='ortho'),axis=1, norm='ortho')\n",
    "    LL0_or, (LH0_or, HL0_or, HH0_or) = pywt.dwt2(image, 'haar')\n",
    "    LL1_or, (LH1_or, HL1_or, HH1_or) = pywt.dwt2(LL0_or, 'haar')\n",
    "    LL2_or, (LH2_or, HL2_or, HH2_or) = pywt.dwt2(LL1_or, 'haar')\n",
    "     \n",
    "\n",
    "    #wat_dct = dct(dct(watermarked,axis=0, norm='ortho'),axis=1, norm='ortho')\n",
    "    LL0_w, (LH0_w, HL0_w, HH0_w) = pywt.dwt2(watermarked, 'haar')\n",
    "    LL1_w, (LH1_w, HL1_w, HH1_w) = pywt.dwt2(LL0_w, 'haar')\n",
    "    LL2_w, (LH2_w, HL2_w, HH2_w) = pywt.dwt2(LL1_w, 'haar')\n",
    "    \n",
    "    extracted_wms = []\n",
    "\n",
    "    if max_layer == 2:\n",
    "        extracted_wms.append(extract_watermark(LH2_or, LH2_w, 2, 0, alpha=alpha, v=v))\n",
    "        extracted_wms.append(extract_watermark(HL2_or, HL2_w, 2, 2, alpha=alpha, v=v))\n",
    "        extracted_wms.append(extract_watermark(HH2_or, HH2_w, 2, 1, alpha=alpha, v=v))\n",
    "    if max_layer >= 1:\n",
    "        extracted_wms.append(extract_watermark(LH1_or, LH1_w, 1, 0, alpha=alpha, v=v))\n",
    "        extracted_wms.append(extract_watermark(HL1_or, HL1_w, 1, 2, alpha=alpha, v=v))\n",
    "        extracted_wms.append(extract_watermark(HH1_or, HH1_w, 1, 1, alpha=alpha, v=v))\n",
    "\n",
    "    extracted_wms.append(extract_watermark(LH0_or, LH0_w, 0, 0, alpha=alpha, v=v))\n",
    "    extracted_wms.append(extract_watermark(HL0_or, HL0_w, 0, 2, alpha=alpha, v=v))\n",
    "    extracted_wms.append(extract_watermark(HH0_or, HH0_w, 0, 1, alpha=alpha, v=v))\n",
    "\n",
    "    return extracted_wms\n",
    "\n",
    "def detection(original, watermarked, attacked, alpha, max_layer):\n",
    "    \n",
    "    w_ex = detect_wm(original, watermarked, alpha, max_layer=max_layer)\n",
    "    w_ex_attacked = detect_wm(original, attacked, alpha, max_layer=max_layer)\n",
    "    \n",
    "    rs = reedsolo.RSCodec(symbols)\n",
    "    decoded_mark = rs.decode(w_ex[0])\n",
    "    ex_mark = np.frombuffer(decoded_mark, dtype=np.uint8)\n",
    "\n",
    "\n",
    "    thr = 0.7045\n",
    "    sim = []\n",
    "    \n",
    "    for w in w_ex_attacked:\n",
    "        w = rs.decode(w)\n",
    "        w = np.frombuffer(w, dtype=np.uint8)\n",
    "        x = similarity(w, ex_mark)\n",
    "        sim.append(x)\n",
    "    \n",
    "    sim = max(sim)\n",
    "\n",
    "    print(sim)\n",
    "    print(similarity(ex_mark,mark))\n",
    "\n",
    "    if sim >= thr:\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4064\n",
      "49.04086183606544\n",
      "4064\n",
      "57.54845150909499\n",
      "4064\n",
      "58.03687008886486\n",
      "4064\n",
      "56.23778788468766\n",
      "4064\n",
      "53.389519797857965\n",
      "4064\n",
      "53.48514422155369\n",
      "4064\n",
      "54.24430088610031\n",
      "4064\n",
      "47.65728897902585\n",
      "4064\n",
      "54.30768341203749\n",
      "4064\n",
      "53.406553091567616\n"
     ]
    }
   ],
   "source": [
    "imgs = [cv2.imread(os.path.join('./sample_imgs', img), 0) for img in os.listdir('./sample_imgs')]\n",
    "mark = np.load('ammhackati.npy')\n",
    "wm_imgs = []\n",
    "alpha = 0.3\n",
    "max_layer = 1\n",
    "wpsnr_wm =[]\n",
    "\n",
    "for img in imgs[:10]:\n",
    "    wm = embedding(img, mark, alpha=alpha, max_layer=max_layer)\n",
    "    wm_imgs.append(wm)\n",
    "    wpsnr_wm.append(wpsnr(img, wm))\n",
    "    print(wpsnr_wm[-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "ReedSolomonError",
     "evalue": "Could not correct message",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mReedSolomonError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[51], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m wi, img \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(wm_imgs, imgs): \n\u001b[1;32m      2\u001b[0m     attacked \u001b[38;5;241m=\u001b[39m jpeg_compression(wi, \u001b[38;5;241m20\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mdetection\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattacked\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_layer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_layer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(wpsnr(attacked, wi))\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result:\n",
      "Cell \u001b[0;32mIn[50], line 181\u001b[0m, in \u001b[0;36mdetection\u001b[0;34m(original, watermarked, attacked, alpha, max_layer)\u001b[0m\n\u001b[1;32m    178\u001b[0m w_ex_attacked \u001b[38;5;241m=\u001b[39m detect_wm(original, attacked, alpha, max_layer\u001b[38;5;241m=\u001b[39mmax_layer)\n\u001b[1;32m    180\u001b[0m rs \u001b[38;5;241m=\u001b[39m reedsolo\u001b[38;5;241m.\u001b[39mRSCodec(symbols)\n\u001b[0;32m--> 181\u001b[0m decoded_mark \u001b[38;5;241m=\u001b[39m \u001b[43mrs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mw_ex\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    182\u001b[0m ex_mark \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfrombuffer(decoded_mark, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39muint8)\n\u001b[1;32m    185\u001b[0m thr \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.7045\u001b[39m\n",
      "File \u001b[0;32m~/.conda/envs/OFF_MDS_ENV/lib/python3.8/site-packages/reedsolo.py:929\u001b[0m, in \u001b[0;36mRSCodec.decode\u001b[0;34m(self, data, nsym, erase_pos, only_erasures)\u001b[0m\n\u001b[1;32m    927\u001b[0m     erase_pos \u001b[38;5;241m=\u001b[39m [x \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnsize \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m erase_pos \u001b[38;5;28;01mif\u001b[39;00m x \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnsize]\n\u001b[1;32m    928\u001b[0m \u001b[38;5;66;03m# Decode/repair this chunk!\u001b[39;00m\n\u001b[0;32m--> 929\u001b[0m rmes, recc, errata_pos \u001b[38;5;241m=\u001b[39m \u001b[43mrs_correct_msg\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnsym\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfcr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfcr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgenerator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merase_pos\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43me_pos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43monly_erasures\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43monly_erasures\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    930\u001b[0m dec\u001b[38;5;241m.\u001b[39mextend(rmes)\n\u001b[1;32m    931\u001b[0m dec_full\u001b[38;5;241m.\u001b[39mextend(rmes\u001b[38;5;241m+\u001b[39mrecc)\n",
      "File \u001b[0;32m~/.conda/envs/OFF_MDS_ENV/lib/python3.8/site-packages/reedsolo.py:760\u001b[0m, in \u001b[0;36mrs_correct_msg\u001b[0;34m(msg_in, nsym, fcr, generator, erase_pos, only_erasures)\u001b[0m\n\u001b[1;32m    758\u001b[0m synd \u001b[38;5;241m=\u001b[39m rs_calc_syndromes(msg_out, nsym, fcr, generator)\n\u001b[1;32m    759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mmax\u001b[39m(synd) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 760\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ReedSolomonError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not correct message\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    761\u001b[0m \u001b[38;5;66;03m# return the successfully decoded message\u001b[39;00m\n\u001b[1;32m    762\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m msg_out[:\u001b[38;5;241m-\u001b[39mnsym], msg_out[\u001b[38;5;241m-\u001b[39mnsym:], erase_pos \u001b[38;5;241m+\u001b[39m err_pos\n",
      "\u001b[0;31mReedSolomonError\u001b[0m: Could not correct message"
     ]
    }
   ],
   "source": [
    "for wi, img in zip(wm_imgs, imgs): \n",
    "    attacked = jpeg_compression(wi, 20)\n",
    "    result = detection(img, wi, attacked, alpha=alpha, max_layer=max_layer)\n",
    "    print(wpsnr(attacked, wi))\n",
    "    if result:\n",
    "        print(\"Found\")\n",
    "    else:\n",
    "        print(\"Not found\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "OFF_MDS_ENV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
